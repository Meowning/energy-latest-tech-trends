7/30 최신기술동향 시작
리드미에 뭐 만들지 정리하고, 서버컴 성능 생각해서 약간 가볍고 빠른 프레임워크, 기술 스택으로만 구성함. 글고 크롤링 가능한 사이트 정리해둠

7/31
어제 정한 스택으로 프론트/백 initial setting 하고
껍데기를 구상하고 필요한 기능을 만드는 게 편할 거 같아서 프론트부터 먼저 함.
근데 할 일도 많고 공부할 시간이 필요해서 많이는 못함...

8/1 ~ 8/3
회사 휴일이라 나도 같이 코딩 휴일함...

8/4
난 이때 scroll-snap이란 용어를 처음 알았다...
암튼 저번주에 공부한 거랑 웹프에서 리액트 다뤘던 기억을 떠올려 Svelte 기반으로 만듦...
JS 기반인거 빼고 약간 다르지만 라우팅 짱
글고 리드미 좀 더 다듬음

8/5
오늘 바빠서 코딩 많이 못함...
RPA 서비스만 하기엔 난이도가 너무 쉬운 거 같아서 OCR + 추출/생성 요약 넣음
약간 모밋 할때 생각난다 ㅎ

8/6
OCR이 말을 안듣는다... 지금 이미지 기반이라서, OCR 전처리에서 안 걸러진 디자인들이 이상하게 인식되고 있음...
그래서 텍스트 기반 pdf면 걍 가져오고, 아니면 OCR 하기로... 정확도는 높아지겠지
글고 하루죙일 전처리만 함. 형태소 분석, 불용어 제거... 아마 추출요약은 키워드로 가지 않을까 싶은데
글고 생성요약은 CPU에서 잘 돌아가는 경량화된 T5 계열... 일단 더 조사해봐야 할 거 같음
일단 추출요약은 단어 빈도 분석으로 하는걸로...!!

8/7
오늘 엄청 뜯어고쳤다...
아무래도 이게 에너지, 기술, 원자력 이런 쪽 도메인이다 보니깐
단어 빈도 분석으로 하니깐, 불용어가 너무 많이 나옴...
지금 샘플로 돌리고 있는 pdf에서 다 걸러진다 해도, 다른 데에서 일일이 다 걸러낼 수가 없으니깐
추출요약 방법을 변경함.

기존에는 형태소로 다 짜르고 단어의 빈도를 확인해서 상위 n개 띄우는 방식이였다면,
좀 더 의미있는 결과를 얻기 위해 이런 식으로 바꿈
① 문장별로 벡터 임베딩(SBERT)
② n개 군집으로 클러스터링
③ 군집별로 중심 임베딩 계산하고 가장 가까운 대표 문장 선택 (거리 계산)

그래서 전처리 방식도 바꼈는데, 기존처럼 형태소 분석을 하지 않고,
- 띄어쓰기 정리 (병렬 배치된 본문들의 경우 줄바꿈이 애매모호해서, 걍 공백 다 없애고 딥러닝 모델로 띄어쓰기 다시 하기)
- 전화번호나 의미없는 숫자 지우기
- 이메일, 웹사이트 주소 지우기
- 문장부호 제외 특수문자 지우기
- 노이즈 (의미없는 문장) 필터링
- 글고 문장 단위로 나눔
    - 이제 보니깐 소숫점도 문장 취급 당해버리네. 이건 수정해야지

이런 식으로 하면 불용어가 많은 키워드보다 의미있는 결과가 나올거라 예상됨
일단 이렇게 해보고, 평가기준이 있으려나... 없겠지... 괜찮은거 같으면 계속 이렇게 쓸거임...
생성형 요약은 또 언제 하지... 일단 문장이 너무 길어서 요약이 안되니깐 그거부터 해결해보자

8/8
내일 ADsP 시험임... 코딩할 시간 없어...

8/11
아 기억났다!!! 지금 추출요약에 들어가는 데이터가 이상하게 들어갔던 거 같은데, 한번 코드리뷰 해봐야겠음
일단 OCR 할때 kss 문장 분리 과정을 이미 했는데, 추출 요약 때 띄어쓰기까지 한 결과만
넘어가서 문장 분리를 한번 더 하는게 보임 (비효율적)
그래서 일단 고쳤고... 플래그를 써야되나? 싶었는데 걍 할려고...
이제 생성형 요약 부분을, 지금은 한 문장으로 되어있는데 부분부분 내서 잘라서 넣을거임
요약 기법은 크게 세가지: Stuff, Refine, Map Reduce 방식
일단 나온 문장이 짧으면 Stuff 방식, 길면 Refine 방식을 채택하는 함수 만들어서 해봐야겠음


글고 첨에 전처리때 맞춤법검사기(네이버)를 넣어봤는데 성능이 안 좋아서 뺐었음
근데 좀 더 찾아보니깐 맞춤법검사기 중에 교차검증(다음+부산대학교) 가능한 소스가 있음
일단 파이썬 라이브러리는 아니고 nodejs로 작동하는 것 같은데, 한번 좀 더 알아봐야겠음...
Docker 서비스로 따로 빼는거 고려도 해야겠음.. 후처리도 필요하니깐

일단 전처리 로직을 다시 생각해볼려고 지피티랑 대화 좀 나눠봄...
왜냐면 아무리 텍스트 기반이여도 문서마다 한 단/두 단/세 단 이상 이렇게 나눠지기도 하고
본문이 없는 페이지인 경우도 있음
그래서 띄어쓰기 다 붙이기 -> spacing -> kss 해도 뭔가 품질이 그닥... 그닥임
원래의 품질을 살리면서도 이쁘게 전처리된 무언가가 필요했음

그래서 내린 결론은? 단 같은 경우는 좌표 기반으로 레이아웃이 n단이다 인지를 하고,
칼럼별로 재정렬시킴(텍스트에선 별 상관없겠지만, 이미지에선 그냥 한 문장 취급되니깐)
그리고 줄바꿈 뒤어있는거 문장부호 없이 끝나면 합치고, 줄바꿈하고,
pykospacing, kss 쓰고.

그리고 생성형 요약 t5-small 기반 한국어 파인튜닝 모델 찾아서 쓰려고 했는데,
Hugging Face에서 모델 다운로드가 잘 안됨...
ㄴ 아니 오프라인 모드가 왜 켜져있어?? 어쩐지 안되더라....
아니네 그거 아니고도 코드스페이스에서 허깅페이스를 막아둠... 왜..??

8/12
허깅페이스 다운로드 이슈는 그냥 인터널서버 에러였던 듯함.. 잘 됨..
일단 한번 다운로드 성공하면 오프라인에서 캐시된거 쓸 수 있도록
그리고 그 단락별로 나눠서 하는거, 스페이스 모듈 때문에 오히려 원래의 의미가 틀어져서 스페이스 모듈을 빼기로 결정.
그렇게 테스트 해봤는데 애초에 단락별로 나눠서 하는 과정에서 단락이 제대로 합쳐지지 않는 듯한 양상을 보여 파이프라인을 예전으로 되돌림 ㅠㅠ
(OCR - 전처리 - 스페이싱 - KSS - 추출요약 - 생성요약)
글고 최대한 본문만 AI 요약으로 넘기기 위해, 앞쪽 내용에서 키워드(목차, TEL, FAX 등)로
다 잘라버리고 마지막 마침표 이후로는 다 날려버림. 그나마 괜찮지 않을까?
ㄴ 생성 요약은 괜찮게 잘 나오는 거 같은데, 추출요약이 많이 이상하게 나온다.

```{
    extractive_summary":"[111] 특히, 최근 글로벌 빅테크 기업과 산업계는 장기 무탄소 전력공급을 확보하기 위해 자가발전, 온 사이트 오프사이트 PPA 등 다양한 방식으로 SMR 전력 도입을 추진하고 있다.\n
    [221] Maxim, Es quire, Outback, Toma hawk, Droptop, Starbucks.\n
    [225] 그건 누구나 안다고 여기고 찾아보지 않는다."
}```

첫번째는 괜찮게 나온 것 같은데, 두번째랑 세번째는 왜 저렇게 나오지?
이래서 사람들이 추출요약 안 쓰나 보다. 아니면 그냥 내가 잘못 코딩한걸지도 ㅎ

생성요약은 CPU에서도 빨리 돌아가고 진짜 괜찮게 나와서, 기존의 한줄 출력을 세줄로 늘렸다.
일단 T5가 text-to-text 모델이고, 지금 쓰는건 한국어로 파인튜닝된 모델인데,
프롬프트도 한글로 주는게 좋을까? 일단 영어로 줬다. 해보고 바꿔야징 ㅎ

---
그리고 양질의 요약을 위해, 디코딩을 좀 만졌다.
얘도 일단 트랜스포머 기반 모델이니깐! encoder-decoder 구조.
너무 짧게 생성되는 것을 막으려고 토큰의 최소 수를 50으로 설정했다.
그리고 max token은... 일단 테스트해보고, 너무 길게 나오면 제한을 둘 예정이다,,,
시간을 아끼면서 품질이 떨어지는 걸 방지하기 위해 떨어지는 추세면 얼리스탑 넣었당.

구조에 대해서는 나중에 더 자세히 정리할란다. (회사컴 스티커 메모에 적어둠..)

아 맞다! 그리고 특정 토큰 이하면(문서가 짧으면) Stuff 방식, 그 이상이면 Refine 방식으로 요약한다. (Refine은 좀 많이 오래 걸려서, 또 사전압축같이 추가적으로 작업을 했는데 나중에 정리할거다)
---

**아 실패했던 n단으로 나눠서 하는 거... 뭔가 컴퓨터비전으로 특징 추출해서 본문만 읽을 수 있게 할 수 있지 않을까??** 라는 생각이 갑자기 든다.

> 엇 재미있는 프로젝트가 생각이 났다. 프로야구 우천취소 예측 프로젝트 어떰??? 오늘 야구보러 가는데 우천취소 되면 화딱지 날 것 같음...