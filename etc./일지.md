7/30 최신기술동향 시작
리드미에 뭐 만들지 정리하고, 서버컴 성능 생각해서 약간 가볍고 빠른 프레임워크, 기술 스택으로만 구성함. 글고 크롤링 가능한 사이트 정리해둠

7/31
어제 정한 스택으로 프론트/백 initial setting 하고
껍데기를 구상하고 필요한 기능을 만드는 게 편할 거 같아서 프론트부터 먼저 함.
근데 할 일도 많고 공부할 시간이 필요해서 많이는 못함...

8/1 ~ 8/3
회사 휴일이라 나도 같이 코딩 휴일함...

8/4
난 이때 scroll-snap이란 용어를 처음 알았다...
암튼 저번주에 공부한 거랑 웹프에서 리액트 다뤘던 기억을 떠올려 Svelte 기반으로 만듦...
JS 기반인거 빼고 약간 다르지만 라우팅 짱
글고 리드미 좀 더 다듬음

8/5
오늘 바빠서 코딩 많이 못함...
RPA 서비스만 하기엔 난이도가 너무 쉬운 거 같아서 OCR + 추출/생성 요약 넣음
약간 모밋 할때 생각난다 ㅎ

8/6
OCR이 말을 안듣는다... 지금 이미지 기반이라서, OCR 전처리에서 안 걸러진 디자인들이 이상하게 인식되고 있음...
그래서 텍스트 기반 pdf면 걍 가져오고, 아니면 OCR 하기로... 정확도는 높아지겠지
글고 하루죙일 전처리만 함. 형태소 분석, 불용어 제거... 아마 추출요약은 키워드로 가지 않을까 싶은데
글고 생성요약은 CPU에서 잘 돌아가는 경량화된 T5 계열... 일단 더 조사해봐야 할 거 같음
일단 추출요약은 단어 빈도 분석으로 하는걸로...!!

8/7
오늘 엄청 뜯어고쳤다...
아무래도 이게 에너지, 기술, 원자력 이런 쪽 도메인이다 보니깐
단어 빈도 분석으로 하니깐, 불용어가 너무 많이 나옴...
지금 샘플로 돌리고 있는 pdf에서 다 걸러진다 해도, 다른 데에서 일일이 다 걸러낼 수가 없으니깐
추출요약 방법을 변경함.

기존에는 형태소로 다 짜르고 단어의 빈도를 확인해서 상위 n개 띄우는 방식이였다면,
좀 더 의미있는 결과를 얻기 위해 이런 식으로 바꿈
① 문장별로 벡터 임베딩(SBERT)
② n개 군집으로 클러스터링
③ 군집별로 중심 임베딩 계산하고 가장 가까운 대표 문장 선택 (거리 계산)

그래서 전처리 방식도 바꼈는데, 기존처럼 형태소 분석을 하지 않고,
- 띄어쓰기 정리 (병렬 배치된 본문들의 경우 줄바꿈이 애매모호해서, 걍 공백 다 없애고 딥러닝 모델로 띄어쓰기 다시 하기)
- 전화번호나 의미없는 숫자 지우기
- 이메일, 웹사이트 주소 지우기
- 문장부호 제외 특수문자 지우기
- 노이즈 (의미없는 문장) 필터링
- 글고 문장 단위로 나눔
    - 이제 보니깐 소숫점도 문장 취급 당해버리네. 이건 수정해야지

이런 식으로 하면 불용어가 많은 키워드보다 의미있는 결과가 나올거라 예상됨
일단 이렇게 해보고, 평가기준이 있으려나... 없겠지... 괜찮은거 같으면 계속 이렇게 쓸거임...
생성형 요약은 또 언제 하지... 일단 문장이 너무 길어서 요약이 안되니깐 그거부터 해결해보자

8/8
내일 ADsP 시험임... 코딩할 시간 없어...
